{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77a2eb3d-7470-4b24-938c-e1e9df929b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILE READING\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "TweetData = pd.read_csv(\"Tweet.csv\")\n",
    "CompanyData = pd.read_csv(\"Company.csv\")\n",
    "Company_TweetData = pd.read_csv(\"Company_Tweet.csv\")\n",
    "CompanyValuesData = pd.read_csv(\"CompanyValues.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81386beb-03db-4123-b78a-3b2c7f91cfb3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3717964, 7) (6, 2) (4336445, 2) (17528, 7)\n"
     ]
    }
   ],
   "source": [
    "print(TweetData.shape,CompanyData.shape,Company_TweetData.shape,CompanyValuesData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a83afcfc-10cf-45c6-8741-db47314f8bb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SEPERATING PRICES INTO OPEN AND CLOSE TO CHECK ON WHICH DAYS WAS PRICE HIGHER THAN PREVIOUS DAY\n",
    "list_of_open_prices = CompanyValuesData['open_value']\n",
    "list_of_close_prices = CompanyValuesData['close_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43ba4c33-2d99-4cf7-8757-914f3f6e66b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CREATED A LABEL FOR THE DATASET BASED ON PRICE MOVEMENT\n",
    "# IF THE PRICE MOVES UP DURING THE DAY = POSITIVE -> 1\n",
    "# IF THE PRICE MOVES DOWN DURING THE DAY = NEGATIVE -> 0\n",
    "price_movement = []\n",
    "price_movement.append(1)\n",
    "for i in range(1,len(list_of_close_prices)):\n",
    "    if(list_of_close_prices[i-1] < list_of_close_prices[i]):\n",
    "        price_movement.append(1)\n",
    "    else:\n",
    "        price_movement.append(0)\n",
    "price_movement_df = pd.DataFrame(price_movement, columns = ['price_movement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7490c8b2-43ed-4388-90a9-738121b6ca7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADDING THE LABEL COLUMN TO THE DATASET\n",
    "CompanyValuesData[\"price_movement\"] = price_movement_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8461c4e7-5788-4388-9d6e-75222abbdf3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'AAPL': 1425013, 'TSLA': 1096868, 'AMZN': 718715, 'GOOG': 392569, 'MSFT': 375711, 'GOOGL': 327569})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "companyTweets = Company_TweetData['ticker_symbol']\n",
    "companyNumberOfMentions = Counter(companyTweets)\n",
    "print(companyNumberOfMentions)\n",
    "df = pd.DataFrame.from_dict(companyNumberOfMentions, orient='index')\n",
    "df.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58884c47-81cc-449d-aa6b-3b21c539514d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JOINING THE TWEET_DATA AND COMPANY_TWEET_DATA TO COMBINE THEM INTO A DATASET OF TWEETS\n",
    "MASTER_DATA_SET_OF_TWEETS = pd.merge(TweetData, Company_TweetData, on=\"tweet_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "707d5013-7bcd-4bca-8613-0d7dda1d7881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4336445 entries, 0 to 4336444\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Dtype \n",
      "---  ------         ----- \n",
      " 0   writer         object\n",
      " 1   post_date      int64 \n",
      " 2   body           object\n",
      " 3   comment_num    int64 \n",
      " 4   retweet_num    int64 \n",
      " 5   like_num       int64 \n",
      " 6   ticker_symbol  object\n",
      "dtypes: int64(4), object(3)\n",
      "memory usage: 264.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# REMOVING TWEET_ID SINCE IT WOULD HAVE NO IMPACT ON STOCK MOVEMENT\n",
    "MASTER_DATA_SET_OF_TWEETS.pop('tweet_id')\n",
    "MASTER_DATA_SET_OF_TWEETS.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7174f9be-1cf7-472d-89e8-be6134f1331e",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_of_all_timestamps = MASTER_DATA_SET_OF_TWEETS['post_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "075ddc27-dd6f-46a4-afbb-2846f366ae29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERTING ALL TIMESTAMPS INTO DATES - SINCE IT'LL BE NEEDED FOR JOINING WITH COMPANY PRICE DATA\n",
    "from datetime import datetime\n",
    "day_date = []\n",
    "for i in set_of_all_timestamps:\n",
    "    dateFormatted = datetime.fromtimestamp(i).isoformat()\n",
    "    dateSliced = dateFormatted[:10]\n",
    "    day_date.append(dateSliced)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6617d822-d2de-4506-948e-bd0b798f8837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPLACING TIMESTAMPS WITH DATES\n",
    "MASTER_DATA_SET_OF_TWEETS.pop('post_date')\n",
    "MASTER_DATA_SET_OF_TWEETS['day_date'] = day_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fb2c8c8-03a4-45ab-8d28-fa9c443f12ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>writer</th>\n",
       "      <th>body</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>retweet_num</th>\n",
       "      <th>like_num</th>\n",
       "      <th>ticker_symbol</th>\n",
       "      <th>day_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VisualStockRSRC</td>\n",
       "      <td>lx21 made $10,008  on $AAPL -Check it out! htt...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KeralaGuy77</td>\n",
       "      <td>Insanity of today weirdo massive selling. $aap...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DozenStocks</td>\n",
       "      <td>S&amp;P100 #Stocks Performance $HD $LOW $SBUX $TGT...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>2015-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ShowDreamCar</td>\n",
       "      <td>$GM $TSLA: Volkswagen Pushes 2014 Record Recal...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>2015-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i_Know_First</td>\n",
       "      <td>Swing Trading: Up To 8.91% Return In 14 Days h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            writer                                               body  \\\n",
       "0  VisualStockRSRC  lx21 made $10,008  on $AAPL -Check it out! htt...   \n",
       "1      KeralaGuy77  Insanity of today weirdo massive selling. $aap...   \n",
       "2      DozenStocks  S&P100 #Stocks Performance $HD $LOW $SBUX $TGT...   \n",
       "3     ShowDreamCar  $GM $TSLA: Volkswagen Pushes 2014 Record Recal...   \n",
       "4     i_Know_First  Swing Trading: Up To 8.91% Return In 14 Days h...   \n",
       "\n",
       "   comment_num  retweet_num  like_num ticker_symbol    day_date  \n",
       "0            0            0         1          AAPL  2015-01-01  \n",
       "1            0            0         0          AAPL  2015-01-01  \n",
       "2            0            0         0          AMZN  2015-01-01  \n",
       "3            0            0         1          TSLA  2015-01-01  \n",
       "4            0            0         1          AAPL  2015-01-01  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MASTER_DATA_SET_OF_TWEETS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f576cb6-0404-4bba-b1c5-8aa0cb51fcdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker_symbol</th>\n",
       "      <th>day_date</th>\n",
       "      <th>close_value</th>\n",
       "      <th>volume</th>\n",
       "      <th>open_value</th>\n",
       "      <th>high_value</th>\n",
       "      <th>low_value</th>\n",
       "      <th>price_movement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020-05-29</td>\n",
       "      <td>317.94</td>\n",
       "      <td>38399530</td>\n",
       "      <td>319.25</td>\n",
       "      <td>321.15</td>\n",
       "      <td>316.47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020-05-28</td>\n",
       "      <td>318.25</td>\n",
       "      <td>33449100</td>\n",
       "      <td>316.77</td>\n",
       "      <td>323.44</td>\n",
       "      <td>315.63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020-05-27</td>\n",
       "      <td>318.11</td>\n",
       "      <td>28236270</td>\n",
       "      <td>316.14</td>\n",
       "      <td>318.71</td>\n",
       "      <td>313.09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>316.73</td>\n",
       "      <td>31380450</td>\n",
       "      <td>323.50</td>\n",
       "      <td>324.24</td>\n",
       "      <td>316.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020-05-22</td>\n",
       "      <td>318.89</td>\n",
       "      <td>20450750</td>\n",
       "      <td>315.77</td>\n",
       "      <td>319.23</td>\n",
       "      <td>315.35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker_symbol    day_date  close_value    volume  open_value  high_value  \\\n",
       "0          AAPL  2020-05-29       317.94  38399530      319.25      321.15   \n",
       "1          AAPL  2020-05-28       318.25  33449100      316.77      323.44   \n",
       "2          AAPL  2020-05-27       318.11  28236270      316.14      318.71   \n",
       "3          AAPL  2020-05-26       316.73  31380450      323.50      324.24   \n",
       "4          AAPL  2020-05-22       318.89  20450750      315.77      319.23   \n",
       "\n",
       "   low_value  price_movement  \n",
       "0     316.47               1  \n",
       "1     315.63               1  \n",
       "2     313.09               0  \n",
       "3     316.50               0  \n",
       "4     315.35               1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CompanyValuesData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4afdb32-1359-4dbe-80db-f127f3c95c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SINCE COMPANY PRICE DATA WAS FOR PAST 10 YEARS (FROM 2010-2020) BUT WE ONLY NEED IT FOR 2015-2020\n",
    "# THEREFORE, DATASET NEEDED TO BE CLEANED\n",
    "\n",
    "recentCompanyValuesData = []\n",
    "count=0\n",
    "\n",
    "for ind in CompanyValuesData.index:\n",
    "    day_date = CompanyValuesData['day_date'][ind]\n",
    "    if(int(day_date[:4])>=2015):\n",
    "        recentCompanyValuesData.append(CompanyValuesData.iloc[ind])\n",
    "    else:\n",
    "        count+=1\n",
    "\n",
    "updatedRecentCompanyValuesData = pd.DataFrame(recentCompanyValuesData) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa7b5ca6-93f8-4f00-9b9b-4075b84ee69e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>writer</th>\n",
       "      <th>body</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>retweet_num</th>\n",
       "      <th>like_num</th>\n",
       "      <th>ticker_symbol</th>\n",
       "      <th>day_date</th>\n",
       "      <th>close_value</th>\n",
       "      <th>volume</th>\n",
       "      <th>open_value</th>\n",
       "      <th>high_value</th>\n",
       "      <th>low_value</th>\n",
       "      <th>price_movement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VisualStockRSRC</td>\n",
       "      <td>lx21 made $10,008  on $AAPL -Check it out! htt...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>110.38</td>\n",
       "      <td>41304780</td>\n",
       "      <td>112.82</td>\n",
       "      <td>113.13</td>\n",
       "      <td>110.21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KeralaGuy77</td>\n",
       "      <td>Insanity of today weirdo massive selling. $aap...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>110.38</td>\n",
       "      <td>41304780</td>\n",
       "      <td>112.82</td>\n",
       "      <td>113.13</td>\n",
       "      <td>110.21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i_Know_First</td>\n",
       "      <td>Swing Trading: Up To 8.91% Return In 14 Days h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>110.38</td>\n",
       "      <td>41304780</td>\n",
       "      <td>112.82</td>\n",
       "      <td>113.13</td>\n",
       "      <td>110.21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aaplstocknews</td>\n",
       "      <td>Swing Trading: Up To 8.91% Return In 14 Days h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>110.38</td>\n",
       "      <td>41304780</td>\n",
       "      <td>112.82</td>\n",
       "      <td>113.13</td>\n",
       "      <td>110.21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iknowfirst</td>\n",
       "      <td>Swing Trading: Up To 8.91% Return In 14 Days h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>110.38</td>\n",
       "      <td>41304780</td>\n",
       "      <td>112.82</td>\n",
       "      <td>113.13</td>\n",
       "      <td>110.21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            writer                                               body  \\\n",
       "0  VisualStockRSRC  lx21 made $10,008  on $AAPL -Check it out! htt...   \n",
       "1      KeralaGuy77  Insanity of today weirdo massive selling. $aap...   \n",
       "2     i_Know_First  Swing Trading: Up To 8.91% Return In 14 Days h...   \n",
       "3    aaplstocknews  Swing Trading: Up To 8.91% Return In 14 Days h...   \n",
       "4       iknowfirst  Swing Trading: Up To 8.91% Return In 14 Days h...   \n",
       "\n",
       "   comment_num  retweet_num  like_num ticker_symbol    day_date  close_value  \\\n",
       "0            0            0         1          AAPL  2015-01-01       110.38   \n",
       "1            0            0         0          AAPL  2015-01-01       110.38   \n",
       "2            0            0         1          AAPL  2015-01-01       110.38   \n",
       "3            0            0         1          AAPL  2015-01-01       110.38   \n",
       "4            0            0         1          AAPL  2015-01-01       110.38   \n",
       "\n",
       "     volume  open_value  high_value  low_value  price_movement  \n",
       "0  41304780      112.82      113.13     110.21               1  \n",
       "1  41304780      112.82      113.13     110.21               1  \n",
       "2  41304780      112.82      113.13     110.21               1  \n",
       "3  41304780      112.82      113.13     110.21               1  \n",
       "4  41304780      112.82      113.13     110.21               1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# COMBINING DIFFERENT TABLES INTO A SINGLE DATASET\n",
    "MASTER_DATA_SET = pd.merge(MASTER_DATA_SET_OF_TWEETS,updatedRecentCompanyValuesData,on=['day_date','ticker_symbol'])\n",
    "MASTER_DATA_SET.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "293ffcad-49b1-4e9b-9740-5be261184e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEPERATING THE LABEL FROM THE MASTER DATASET\n",
    "Label = MASTER_DATA_SET.pop('price_movement')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ada05cd-58a4-41bf-8dcb-e38ede13b276",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           AAPL\n",
       "1           AAPL\n",
       "2           AAPL\n",
       "3           AAPL\n",
       "4           AAPL\n",
       "           ...  \n",
       "4335719    GOOGL\n",
       "4335720    GOOGL\n",
       "4335721    GOOGL\n",
       "4335722    GOOGL\n",
       "4335723    GOOGL\n",
       "Name: ticker_symbol, Length: 4335724, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.model_selection as model_selection\n",
    "\n",
    "# FUTHER REFINING THE DATASET - COALESCING 2 COLUMNS INTO ONE AND REMOVING THE OTHERS NOT REQUIRED ONES\n",
    "MASTER_DATA_SET['max_diff'] = MASTER_DATA_SET['high_value'] - MASTER_DATA_SET['low_value']\n",
    "MASTER_DATA_SET.pop('low_value')\n",
    "MASTER_DATA_SET.pop('high_value')\n",
    "MASTER_DATA_SET.pop('ticker_symbol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fd9b31b-cea1-4a71-adb4-cfb64fbde2c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MASTER_DATA_SET.head()\n",
    "\n",
    "# SPLITTING INTO TRAIN AND TEST DATA\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(MASTER_DATA_SET, Label, train_size=0.65, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1932c11a-c39d-4041-8fb9-7e3ce88c1d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweet_body_df = X_train['body']\n",
    "Tweet_comment_num_df = X_train['comment_num']\n",
    "Tweet_retweet_num_df = X_train['retweet_num']\n",
    "Tweet_like_num_df = X_train['like_num']\n",
    "pre_processed_Tweet_body_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8999e8cc-efe6-46cc-989c-5da2db448a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacytextblob.spacytextblob.SpacyTextBlob at 0x22415454700>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "import re\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# LOADING SPACYTEXTBLOB AND VADERSENTIMENT NLP MODELS \n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe('spacytextblob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "886f91b6-31ab-41e1-9280-267f166207b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[=====                                                                   ]   7%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n",
      "[                                                                        ]   0%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[                                                                        ]   0%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter 3\n",
      "Total runtime of the program is 270.9745762348175\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords  \n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import time\n",
    "import progressbar\n",
    "\n",
    "length = 100000\n",
    "bar = progressbar.ProgressBar(maxval=length, \\\n",
    "    widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n",
    "\n",
    "begintime = time.time()\n",
    "print(\"enter 1\")\n",
    "english_stopwords = stopwords.words('english')\n",
    "snow_stemmer = SnowballStemmer(language='english')\n",
    "security_list = [\"goog\",\"googl\",\"aapl\",\"msft\",\"tsla\",\"amzn\"]\n",
    "\n",
    "count = 0\n",
    "polarity_list = []\n",
    "tweet_body_preprocessed = []\n",
    "bar.start()\n",
    "for ind in range(length):#len(Tweet_body_df)):\n",
    "    bar.update(ind+1)\n",
    "    tweet = Tweet_body_df.iloc[ind]\n",
    "    tweet = re.sub('https?', ' https', tweet)\n",
    "    tweet_list = tweet.split('$')\n",
    "    tweet_list_cleaned = [i.strip().lower() for i in tweet_list if (i.strip().lower() in security_list or len(i.strip()) >= 5)]\n",
    "    tweet = \" \".join(tweet_list_cleaned)\n",
    "    tweet_body_preprocessed.append(tweet)\n",
    "bar.finish()\n",
    "print(\"enter 2\")\n",
    "bar.start()\n",
    "tweet_body_preprocessed_df = pd.DataFrame(tweet_body_preprocessed,columns = ['body'])\n",
    "polarity_spacy_blob_list = []\n",
    "count=0\n",
    "for doc in nlp.pipe(Tweet_body_df.head(length), n_process = 4, batch_size=length//10,disable = [\n",
    "      'tagger','parser','ner','entity_linker',\n",
    "      'entity_ruler','textcat','textcat_multilabel',\n",
    "      'lemmatizer','morphologizer','attribute_ruler','senter',\n",
    "      'sentencizer','tok2vec','transformer']):\n",
    "    bar.update(ind+1)\n",
    "    polarity_spacy_blob_list.append(doc._.polarity)\n",
    "bar.finish()\n",
    "\n",
    "bar.start()\n",
    "polarity_list = []\n",
    "print(\"enter 3\")\n",
    "bar.start()\n",
    "for ind in range(length):#len(Tweet_body_df)):\n",
    "    multiplier = 4 * Tweet_comment_num_df.iloc[ind] \\\n",
    "        + 2 * Tweet_retweet_num_df.iloc[ind] \\\n",
    "        + Tweet_like_num_df.iloc[ind]\n",
    "    \n",
    "    if(multiplier == 0):\n",
    "        mutliplier = 1\n",
    "    \n",
    "    polarity_spacy_blob = polarity_spacy_blob_list[ind] * multiplier\n",
    "    \n",
    "    vs = analyzer.polarity_scores(tweet)\n",
    "    polarity_vader_sentiment = (vs['pos'] - vs['neg']) * multiplier\n",
    "    \n",
    "    avg_polarity = (polarity_vader_sentiment + polarity_spacy_blob) / 2\n",
    "    #Flair didn't work not that useful\n",
    "    polarity_list.append(avg_polarity * 2)\n",
    "bar.finish()\n",
    "end = time.time()\n",
    "# total time taken\n",
    "print(f\"Total runtime of the program is {end - begintime}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7bdd3106-a82b-4486-a207-3287a3550a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.497320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.614617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-326.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.104000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>973.236000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            polarity\n",
       "count  100000.000000\n",
       "mean        0.497320\n",
       "std         6.614617\n",
       "min      -326.290000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         0.104000\n",
       "max       973.236000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polarity_df = pd.DataFrame(polarity_list, columns = ['polarity'])\n",
    "polarity_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2bcaf657-7b8b-4a3f-824e-03525c1895d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import multiprocessing\\nimport time\\nimport progressbar\\nimport spacy\\nfrom spacytextblob.spacytextblob import SpacyTextBlob\\n\\nlength = 10000\\n\\ndef preprocess_pipe(texts):\\n    preproc_pipe = []\\n    for doc in nlp.pipe(texts, n_process = 2, batch_size=1000,disable = [\\'tagger\\',\\'parser\\',\\'ner\\',\\'entity_linker\\',\\'entity_ruler\\',\\'textcat\\',\\'textcat_multilabel\\',\\'lemmatizer\\',\\'morphologizer\\',\\'attribute_ruler\\',\\'senter\\',\\'sentencizer\\',\\'tok2vec\\',\\'transformer\\']):\\n        bar.update(ind+1)\\n        preproc_pipe.append(doc._.polarity)\\n        \\nbar = progressbar.ProgressBar(maxval=length,     widgets=[progressbar.Bar(\\'=\\', \\'[\\', \\']\\'), \\' \\', progressbar.Percentage()])\\nbegintime = time.time()\\nbar.start()\\npreprocess_pipe(Tweet_body_df.head(length))\\nbar.finish()\\nend = time.time()\\n# total time taken\\nprint(f\"Total runtime of the program is {end - begintime}\")'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import multiprocessing\n",
    "import time\n",
    "import progressbar\n",
    "import spacy\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "\n",
    "length = 10000\n",
    "\n",
    "def preprocess_pipe(texts):\n",
    "    preproc_pipe = []\n",
    "    for doc in nlp.pipe(texts, n_process = 2, batch_size=1000,disable = ['tagger','parser','ner','entity_linker','entity_ruler','textcat','textcat_multilabel','lemmatizer','morphologizer','attribute_ruler','senter','sentencizer','tok2vec','transformer']):\n",
    "        bar.update(ind+1)\n",
    "        preproc_pipe.append(doc._.polarity)\n",
    "        \n",
    "bar = progressbar.ProgressBar(maxval=length, \\\n",
    "    widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n",
    "begintime = time.time()\n",
    "bar.start()\n",
    "preprocess_pipe(Tweet_body_df.head(length))\n",
    "bar.finish()\n",
    "end = time.time()\n",
    "# total time taken\n",
    "print(f\"Total runtime of the program is {end - begintime}\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9140e35a-2f8b-447a-a6a9-8844f44e8021",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import re                                \\nimport string    \\nimport time\\n\\nfrom nltk.corpus import stopwords  \\nfrom nltk.stem.snowball import SnowballStemmer\\n\\nbegintime = time.time()\\nenglish_stopwords = stopwords.words(\\'english\\')\\nsnow_stemmer = SnowballStemmer(language=\\'english\\')\\ncount = 0\\n#lenght of largest tweet = 57 words\\nfor ind in range(1,1):\\n    #len(Tweet_body_df)):\\n    tweet = Tweet_body_df.iloc[ind]\\n    tweet = re.sub(r\\'https?:\\\\/\\\\/.*[\\r\\n]*\\', \\'\\', tweet)\\n    tweet = re.sub(\\'[^a-zA-z]\\',\\' \\',tweet)\\n    tweet = tweet.split()\\n    tweet = [snow_stemmer.stem(i.lower()) for i in tweet if i not in english_stopwords]\\n    tweet = list(set(tweet))\\n    len_to_pad = 58 - len(tweet)\\n    pad_list = [ \"*\" for i in range(len_to_pad)]\\n    tweet += pad_list\\n    tweet_str = \" \".join(tweet)\\n    pre_processed_Tweet_body_list.append(tweet_str)\\n\\nend = time.time()\\n# total time taken\\nprint(f\"Total runtime of the program is {end - begintime}\")'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import re                                \n",
    "import string    \n",
    "import time\n",
    "\n",
    "from nltk.corpus import stopwords  \n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "begintime = time.time()\n",
    "english_stopwords = stopwords.words('english')\n",
    "snow_stemmer = SnowballStemmer(language='english')\n",
    "count = 0\n",
    "#lenght of largest tweet = 57 words\n",
    "for ind in range(1,1):\n",
    "    #len(Tweet_body_df)):\n",
    "    tweet = Tweet_body_df.iloc[ind]\n",
    "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "    tweet = re.sub('[^a-zA-z]',' ',tweet)\n",
    "    tweet = tweet.split()\n",
    "    tweet = [snow_stemmer.stem(i.lower()) for i in tweet if i not in english_stopwords]\n",
    "    tweet = list(set(tweet))\n",
    "    len_to_pad = 58 - len(tweet)\n",
    "    pad_list = [ \"*\" for i in range(len_to_pad)]\n",
    "    tweet += pad_list\n",
    "    tweet_str = \" \".join(tweet)\n",
    "    pre_processed_Tweet_body_list.append(tweet_str)\n",
    "\n",
    "end = time.time()\n",
    "# total time taken\n",
    "print(f\"Total runtime of the program is {end - begintime}\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "791c11bf-520f-48fc-b06a-871119c907a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\\n\\nanalyzer = SentimentIntensityAnalyzer()\\nsentence = \"The food was great!\" \\nvs = analyzer.polarity_scores(sentence)\\nprint(\"{:-<65} {}\".format(sentence, str(vs)))\\n\\nsentence_new = \"$AMZN Trending Now 11/16/2016! If you follow AMZN Share your opinions hereGo here: ---->  http://dlvr.it/MgvBgq\"\\nvs = analyzer.polarity_scores(sentence_new)\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "sentence = \"The food was great!\" \n",
    "vs = analyzer.polarity_scores(sentence)\n",
    "print(\"{:-<65} {}\".format(sentence, str(vs)))\n",
    "\n",
    "sentence_new = \"$AMZN Trending Now 11/16/2016! If you follow AMZN Share your opinions hereGo here: ---->  http://dlvr.it/MgvBgq\"\n",
    "vs = analyzer.polarity_scores(sentence_new)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b673616e-f387-4f4d-bfef-7bbc06fc570c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pre_processed_Tweet_body_df = pd.DataFrame(pre_processed_Tweet_body_list,columns=[\"Pre-Processed-Body\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9fb89421-1a3b-42cb-a7a5-0d5f121fc3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "################ TEXT PRE PROCESSING COMPLETE ##########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb3e7279-0fc5-49bb-ba6c-38b1822b238f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         polarity\n",
      "1330486  0.000000\n",
      "638815   0.000000\n",
      "2414411  0.000000\n",
      "1692356  0.000000\n",
      "3056858  0.000000\n",
      "...           ...\n",
      "1770859  0.618667\n",
      "3426449  0.000000\n",
      "3757358  0.052000\n",
      "2099106  1.052000\n",
      "1535966  0.520667\n",
      "\n",
      "[100000 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "X_train_short = X_train.head(100000)\n",
    "polarity_df = polarity_df.set_index(X_train_short.index)                      \n",
    "X_train_short['polarity'] = polarity_df['polarity']\n",
    "X_train_short.pop('body')\n",
    "print(polarity_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "198f739f-02e4-4e51-8b45-b5f2d80148d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_df = X_train_short['writer']\n",
    "\n",
    "writer_id = 1\n",
    "writer_list = []\n",
    "writer_id_list = []\n",
    "for ind in range(len(writer_df)):\n",
    "    writer_name = writer_df.iloc[ind]\n",
    "    if writer_name not in writer_list:\n",
    "        writer_list.append(writer_name)\n",
    "        writer_id_list.append(writer_id)\n",
    "        writer_id+=1\n",
    "    else:\n",
    "        index = writer_list.index(writer_name)\n",
    "        writer_again = writer_id_list[index]\n",
    "        writer_list.append(writer_name)\n",
    "        writer_id_list.append(writer_again)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e577c697-d074-4567-a09d-36851ee0b392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_num</th>\n",
       "      <th>retweet_num</th>\n",
       "      <th>like_num</th>\n",
       "      <th>day_date</th>\n",
       "      <th>close_value</th>\n",
       "      <th>volume</th>\n",
       "      <th>open_value</th>\n",
       "      <th>max_diff</th>\n",
       "      <th>polarity</th>\n",
       "      <th>writer_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1330486</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-07-13</td>\n",
       "      <td>96.87</td>\n",
       "      <td>25879680</td>\n",
       "      <td>97.41</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638815</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-09-20</td>\n",
       "      <td>260.62</td>\n",
       "      <td>3760644</td>\n",
       "      <td>257.96</td>\n",
       "      <td>6.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2414411</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-11-02</td>\n",
       "      <td>299.26</td>\n",
       "      <td>19771280</td>\n",
       "      <td>300.13</td>\n",
       "      <td>16.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1692356</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-11-17</td>\n",
       "      <td>756.40</td>\n",
       "      <td>3662939</td>\n",
       "      <td>749.32</td>\n",
       "      <td>9.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3056858</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-08-18</td>\n",
       "      <td>217.58</td>\n",
       "      <td>35034410</td>\n",
       "      <td>213.44</td>\n",
       "      <td>4.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         comment_num  retweet_num  like_num    day_date  close_value  \\\n",
       "1330486            0            0         0  2016-07-13        96.87   \n",
       "638815             0            0         0  2015-09-20       260.62   \n",
       "2414411            0            0         0  2017-11-02       299.26   \n",
       "1692356            0            0         0  2016-11-17       756.40   \n",
       "3056858            0            0         0  2018-08-18       217.58   \n",
       "\n",
       "           volume  open_value  max_diff  polarity  writer_ids  \n",
       "1330486  25879680       97.41      0.83       0.0           1  \n",
       "638815    3760644      257.96      6.32       0.0           2  \n",
       "2414411  19771280      300.13     16.06       0.0           3  \n",
       "1692356   3662939      749.32      9.50       0.0           4  \n",
       "3056858  35034410      213.44      4.79       0.0           5  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writers_df = pd.DataFrame(writer_id_list, columns=['writer_ids'])\n",
    "writers_df = writers_df.set_index(X_train_short.index)\n",
    "X_train_short['writer_ids'] = writers_df\n",
    "X_train_short.pop('writer')\n",
    "X_train_short.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6f8ee137-19f0-47b6-b3d0-60017618cbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_date_df = X_train_short['day_date']\n",
    "day_date_list = []\n",
    "\n",
    "for ind in range(len(X_train_short)):\n",
    "    string_date = day_date_df.iloc[ind]\n",
    "    string_date = string_date.replace(\"-\",\"\")\n",
    "    day_date_list.append(int(string_date))\n",
    "    \n",
    "day_date_df = pd.DataFrame(day_date_list,columns=['day_date'])\n",
    "day_date_df = day_date_df.set_index(X_train_short.index)\n",
    "\n",
    "X_train_short['day_date'] = day_date_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "504b3865-21ae-4fe8-b17e-634824a0d2a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import spacy\\nfrom spacytextblob.spacytextblob import SpacyTextBlob\\n\\nnlp = spacy.load('en_core_web_sm')\\nnlp.add_pipe('spacytextblob')\\ntext = 'I had a really horrible day. It was the worst day ever! But every now and then I have a really good day that makes me happy.'\\ndoc = nlp(text, disable = ['tagger','parser','ner','entity_linker','entity_ruler','textcat','textcat_multilabel','lemmatizer','morphologizer','attribute_ruler','senter','sentencizer','tok2vec','transformer'])\\ndoc2 = nlp(text)\\nprint(doc2._.polarity)\\nprint(doc._.polarity)\\n\\ntext = 'I had a really horrible day'\\ndoc = nlp(text, disable = ['parser','ner','entity_linker','entity_ruler','textcat','textcat_multilabel','lemmatizer','morphologizer','attribute_ruler','senter','sentencizer','tok2vec','transformer'])\\ndoc2 = nlp(text)\\nprint(doc2._.polarity)\\nprint(doc._.polarity)\\n\\ntext = 'I had a good day'\\ndoc = nlp(text, disable = ['parser','ner','entity_linker','entity_ruler','textcat','textcat_multilabel','lemmatizer','morphologizer','attribute_ruler','senter','sentencizer','tok2vec','transformer'])\\ndoc2 = nlp(text)\\nprint(doc2._.polarity)\\nprint(doc._.polarity)\\n\\ntext = 'Insanity of today weirdo massive selling. '\\ndoc = nlp(text, disable = ['parser','ner','entity_linker','entity_ruler','textcat','textcat_multilabel','lemmatizer','morphologizer','attribute_ruler','senter','sentencizer','tok2vec','transformer'])\\ndoc2 = nlp(text)\\nprint(doc2._.polarity)\\nprint(doc._.polarity)\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import spacy\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe('spacytextblob')\n",
    "text = 'I had a really horrible day. It was the worst day ever! But every now and then I have a really good day that makes me happy.'\n",
    "doc = nlp(text, disable = ['tagger','parser','ner','entity_linker','entity_ruler','textcat','textcat_multilabel','lemmatizer','morphologizer','attribute_ruler','senter','sentencizer','tok2vec','transformer'])\n",
    "doc2 = nlp(text)\n",
    "print(doc2._.polarity)\n",
    "print(doc._.polarity)\n",
    "\n",
    "text = 'I had a really horrible day'\n",
    "doc = nlp(text, disable = ['parser','ner','entity_linker','entity_ruler','textcat','textcat_multilabel','lemmatizer','morphologizer','attribute_ruler','senter','sentencizer','tok2vec','transformer'])\n",
    "doc2 = nlp(text)\n",
    "print(doc2._.polarity)\n",
    "print(doc._.polarity)\n",
    "\n",
    "text = 'I had a good day'\n",
    "doc = nlp(text, disable = ['parser','ner','entity_linker','entity_ruler','textcat','textcat_multilabel','lemmatizer','morphologizer','attribute_ruler','senter','sentencizer','tok2vec','transformer'])\n",
    "doc2 = nlp(text)\n",
    "print(doc2._.polarity)\n",
    "print(doc._.polarity)\n",
    "\n",
    "text = 'Insanity of today weirdo massive selling. '\n",
    "doc = nlp(text, disable = ['parser','ner','entity_linker','entity_ruler','textcat','textcat_multilabel','lemmatizer','morphologizer','attribute_ruler','senter','sentencizer','tok2vec','transformer'])\n",
    "doc2 = nlp(text)\n",
    "print(doc2._.polarity)\n",
    "print(doc._.polarity)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3cc95a34-b119-4291-8271-0e46dc54e1bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_num</th>\n",
       "      <th>retweet_num</th>\n",
       "      <th>like_num</th>\n",
       "      <th>day_date</th>\n",
       "      <th>close_value</th>\n",
       "      <th>volume</th>\n",
       "      <th>open_value</th>\n",
       "      <th>max_diff</th>\n",
       "      <th>polarity</th>\n",
       "      <th>writer_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1330486</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20160713</td>\n",
       "      <td>96.87</td>\n",
       "      <td>25879680</td>\n",
       "      <td>97.41</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638815</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20150920</td>\n",
       "      <td>260.62</td>\n",
       "      <td>3760644</td>\n",
       "      <td>257.96</td>\n",
       "      <td>6.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2414411</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20171102</td>\n",
       "      <td>299.26</td>\n",
       "      <td>19771280</td>\n",
       "      <td>300.13</td>\n",
       "      <td>16.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1692356</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20161117</td>\n",
       "      <td>756.40</td>\n",
       "      <td>3662939</td>\n",
       "      <td>749.32</td>\n",
       "      <td>9.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3056858</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20180818</td>\n",
       "      <td>217.58</td>\n",
       "      <td>35034410</td>\n",
       "      <td>213.44</td>\n",
       "      <td>4.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         comment_num  retweet_num  like_num  day_date  close_value    volume  \\\n",
       "1330486            0            0         0  20160713        96.87  25879680   \n",
       "638815             0            0         0  20150920       260.62   3760644   \n",
       "2414411            0            0         0  20171102       299.26  19771280   \n",
       "1692356            0            0         0  20161117       756.40   3662939   \n",
       "3056858            0            0         0  20180818       217.58  35034410   \n",
       "\n",
       "         open_value  max_diff  polarity  writer_ids  \n",
       "1330486       97.41      0.83       0.0           1  \n",
       "638815       257.96      6.32       0.0           2  \n",
       "2414411      300.13     16.06       0.0           3  \n",
       "1692356      749.32      9.50       0.0           4  \n",
       "3056858      213.44      4.79       0.0           5  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_short.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9833d878-ebb9-4677-9a7c-0a77cbea65d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_short = y_train.head(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c7639d04-daf9-4935-bf95-d444e81a6dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_short = X_test.head(length)\n",
    "Y_test_short = y_test.head(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "796eb12f-9fdc-40c6-af82-743b1745d9c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n",
      "[========================================================================] 100%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total runtime of the program is 349.57650876045227\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_num</th>\n",
       "      <th>retweet_num</th>\n",
       "      <th>like_num</th>\n",
       "      <th>day_date</th>\n",
       "      <th>close_value</th>\n",
       "      <th>volume</th>\n",
       "      <th>open_value</th>\n",
       "      <th>max_diff</th>\n",
       "      <th>writer_ids</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>417297</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20150622</td>\n",
       "      <td>127.61</td>\n",
       "      <td>33976180</td>\n",
       "      <td>127.49</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718212</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20151025</td>\n",
       "      <td>719.33</td>\n",
       "      <td>6330015</td>\n",
       "      <td>750.06</td>\n",
       "      <td>34.56</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2247889</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>20170808</td>\n",
       "      <td>365.22</td>\n",
       "      <td>7431838</td>\n",
       "      <td>357.53</td>\n",
       "      <td>11.18</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900936</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20160129</td>\n",
       "      <td>55.09</td>\n",
       "      <td>83559310</td>\n",
       "      <td>54.73</td>\n",
       "      <td>1.09</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422319</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20150624</td>\n",
       "      <td>128.11</td>\n",
       "      <td>55077520</td>\n",
       "      <td>127.21</td>\n",
       "      <td>2.68</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         comment_num  retweet_num  like_num  day_date  close_value    volume  \\\n",
       "417297             0            0         0  20150622       127.61  33976180   \n",
       "718212             0            0         0  20151025       719.33   6330015   \n",
       "2247889            0            0         2  20170808       365.22   7431838   \n",
       "900936             0            2         1  20160129        55.09  83559310   \n",
       "422319             0            0         0  20150624       128.11  55077520   \n",
       "\n",
       "         open_value  max_diff  writer_ids  polarity  \n",
       "417297       127.49      0.98           1       0.0  \n",
       "718212       750.06     34.56           2       0.0  \n",
       "2247889      357.53     11.18           3       0.0  \n",
       "900936        54.73      1.09           4       0.0  \n",
       "422319       127.21      2.68           5       0.0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_short\n",
    "\n",
    "#processing the dataset\n",
    "\n",
    "#WRITERS\n",
    "writer_df = X_test_short['writer']\n",
    "writer_id = 1\n",
    "writer_list = []\n",
    "writer_id_list = []\n",
    "for ind in range(len(writer_df)):\n",
    "    writer_name = writer_df.iloc[ind]\n",
    "    if writer_name not in writer_list:\n",
    "        writer_list.append(writer_name)\n",
    "        writer_id_list.append(writer_id)\n",
    "        writer_id+=1\n",
    "    else:\n",
    "        index = writer_list.index(writer_name)\n",
    "        writer_again = writer_id_list[index]\n",
    "        writer_list.append(writer_name)\n",
    "        writer_id_list.append(writer_again)\n",
    "writers_df = pd.DataFrame(writer_id_list, columns=['writer_ids'])\n",
    "writers_df = writers_df.set_index(X_test_short.index)\n",
    "X_test_short['writer_ids'] = writers_df\n",
    "X_test_short.pop('writer')\n",
    "X_test_short.head()\n",
    "        \n",
    "#BODY\n",
    "length = 100000\n",
    "bar = progressbar.ProgressBar(maxval=length, \\\n",
    "    widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n",
    "\n",
    "begintime = time.time()\n",
    "\n",
    "english_stopwords = stopwords.words('english')\n",
    "snow_stemmer = SnowballStemmer(language='english')\n",
    "security_list = [\"goog\",\"googl\",\"aapl\",\"msft\",\"tsla\",\"amzn\"]\n",
    "\n",
    "count = 0\n",
    "polarity_list = []\n",
    "tweet_body_preprocessed = []\n",
    "bar.start()\n",
    "for ind in range(length):#len(Tweet_body_df)):\n",
    "    bar.update(ind+1)\n",
    "    tweet = Tweet_body_df.iloc[ind]\n",
    "    tweet = re.sub('https?', ' https', tweet)\n",
    "    tweet_list = tweet.split('$')\n",
    "    tweet_list_cleaned = [i.strip().lower() for i in tweet_list if (i.strip().lower() in security_list or len(i.strip()) >= 5)]\n",
    "    tweet = \" \".join(tweet_list_cleaned)\n",
    "    tweet_body_preprocessed.append(tweet)\n",
    "bar.finish()\n",
    "\n",
    "bar.start()\n",
    "tweet_body_preprocessed_df = pd.DataFrame(tweet_body_preprocessed,columns = ['body'])\n",
    "polarity_spacy_blob_list = []\n",
    "count=0\n",
    "for doc in nlp.pipe(Tweet_body_df.head(length), n_process = 4, batch_size=length//10,disable = [\n",
    "      'tagger','parser','ner','entity_linker',\n",
    "      'entity_ruler','textcat','textcat_multilabel',\n",
    "      'lemmatizer','morphologizer','attribute_ruler','senter',\n",
    "      'sentencizer','tok2vec','transformer']):\n",
    "    bar.update(ind+1)\n",
    "    polarity_spacy_blob_list.append(doc._.polarity)\n",
    "bar.finish()\n",
    "\n",
    "bar.start()\n",
    "polarity_list = []\n",
    "bar.start()\n",
    "for ind in range(length):#len(Tweet_body_df)):\n",
    "    bar.update(ind+1)\n",
    "    multiplier = 4 * Tweet_comment_num_df.iloc[ind] \\\n",
    "        + 2 * Tweet_retweet_num_df.iloc[ind] \\\n",
    "        + Tweet_like_num_df.iloc[ind]\n",
    "    \n",
    "    if(multiplier == 0):\n",
    "        mutliplier = 1\n",
    "    \n",
    "    polarity_spacy_blob = polarity_spacy_blob_list[ind] * multiplier\n",
    "    \n",
    "    vs = analyzer.polarity_scores(tweet)\n",
    "    polarity_vader_sentiment = (vs['pos'] - vs['neg']) * multiplier\n",
    "    \n",
    "    avg_polarity = (polarity_vader_sentiment + polarity_spacy_blob) / 2\n",
    "    #Flair didn't work not that useful\n",
    "    polarity_list.append(avg_polarity * 2)\n",
    "    \n",
    "bar.finish()\n",
    "end = time.time()\n",
    "# total time taken\n",
    "print(f\"Total runtime of the program is {end - begintime}\")\n",
    "polarity_df = pd.DataFrame(polarity_list, columns = ['polarity'])\n",
    "polarity_df = polarity_df.set_index(X_test_short.index)                      \n",
    "X_test_short['polarity'] = polarity_df['polarity']\n",
    "X_test_short.pop('body')\n",
    "      \n",
    "#day_date\n",
    "day_date_df = X_test_short['day_date']\n",
    "day_date_list = []\n",
    "\n",
    "for ind in range(len(X_test_short)):\n",
    "    string_date = day_date_df.iloc[ind]\n",
    "    string_date = string_date.replace(\"-\",\"\")\n",
    "    day_date_list.append(int(string_date))\n",
    "    \n",
    "day_date_df = pd.DataFrame(day_date_list,columns=['day_date'])\n",
    "day_date_df = day_date_df.set_index(X_test_short.index)\n",
    "\n",
    "X_test_short['day_date'] = day_date_df\n",
    "\n",
    "X_test_short.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "18eb0402-60a6-4032-9e84-1aa237c5a0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_x_train = X_train_short\n",
    "lr_y_train = Y_train_short\n",
    "lr_x_test = X_test_short\n",
    "lr_y_test = Y_test_short\n",
    "\n",
    "tree_x_train = X_train_short\n",
    "tree_y_train = Y_train_short\n",
    "tree_x_test = X_test_short\n",
    "tree_y_test = Y_test_short\n",
    "\n",
    "svm_x_train = X_train_short\n",
    "svm_y_train = Y_train_short\n",
    "svm_x_test = X_test_short\n",
    "svm_y_test = Y_test_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "88a3be67-2bc3-4653-a093-1beae134198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the class\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# instantiate the model (using the default parameters)\n",
    "logreg = LogisticRegression(solver='lbfgs', max_iter=100000)\n",
    "\n",
    "# fit the model with data\n",
    "logreg.fit(lr_x_train,lr_y_train)\n",
    "\n",
    "#\n",
    "y_pred=logreg.predict(lr_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "44ee6a40-b03e-42b6-8616-80e63b4fb89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[54875     0]\n",
      " [45125     0]]\n",
      "Accuracy: 0.54875\n"
     ]
    }
   ],
   "source": [
    "# import the metrics class\n",
    "from sklearn import metrics\n",
    "cnf_matrix = metrics.confusion_matrix(Y_test_short, y_pred)\n",
    "print(cnf_matrix)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(lr_y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b177c192-c87b-41d6-9fba-e9277f969f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.90706\n"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "\n",
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(tree_x_train,tree_y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(tree_x_test)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(tree_y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c8155204-2718-4dfd-9f00-050d5543e76b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#Import svm model\\nfrom sklearn import svm\\n\\n#Create a svm Classifier\\nclf = svm.SVC(kernel=\\'linear\\') # Linear Kernel\\n\\n#Train the model using the training sets\\nclf.fit(svm_x_train.head(100),svm_y_train.head(100))\\n\\n#Predict the response for test dataset\\ny_pred = clf.predict(svm_x_test.head(100))\\n\\n#Import scikit-learn metrics module for accuracy calculation\\nfrom sklearn import metrics\\n\\n# Model Accuracy: how often is the classifier correct?\\nprint(\"Accuracy:\",metrics.accuracy_score(svm_y_test.head(100), y_pred))'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#Import svm model\n",
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(svm_x_train.head(100),svm_y_train.head(100))\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(svm_x_test.head(100))\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(svm_y_test.head(100), y_pred))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee31fe8-22a7-40a9-a3e3-d11eac54238b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
